{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install langchain openai","metadata":{"execution":{"iopub.status.busy":"2023-10-22T14:46:02.956059Z","iopub.execute_input":"2023-10-22T14:46:02.956395Z","iopub.status.idle":"2023-10-22T14:46:33.528461Z","shell.execute_reply.started":"2023-10-22T14:46:02.956369Z","shell.execute_reply":"2023-10-22T14:46:33.527390Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting langchain\n  Downloading langchain-0.0.320-py3-none-any.whl (1.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hCollecting openai\n  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.17)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.8.4)\nRequirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.7.0)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.2)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.0)\nCollecting jsonpatch<2.0,>=1.33 (from langchain)\n  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\nCollecting langsmith<0.1.0,>=0.0.43 (from langchain)\n  Downloading langsmith-0.0.49-py3-none-any.whl (41 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.23.5)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.10.9)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai) (4.66.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\nRequirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.4)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.3.0)\nRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.1.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.6.3)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2023.7.22)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\nRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (21.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (3.0.9)\nInstalling collected packages: jsonpatch, langsmith, openai, langchain\n  Attempting uninstall: jsonpatch\n    Found existing installation: jsonpatch 1.32\n    Uninstalling jsonpatch-1.32:\n      Successfully uninstalled jsonpatch-1.32\nSuccessfully installed jsonpatch-1.33 langchain-0.0.320 langsmith-0.0.49 openai-0.28.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install tiktoken","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:03:44.094344Z","iopub.execute_input":"2023-10-22T15:03:44.094785Z","iopub.status.idle":"2023-10-22T15:03:58.312431Z","shell.execute_reply.started":"2023-10-22T15:03:44.094726Z","shell.execute_reply":"2023-10-22T15:03:58.311164Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Collecting tiktoken\n  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.6.3)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\nInstalling collected packages: tiktoken\nSuccessfully installed tiktoken-0.5.1\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Conversation Buffer","metadata":{}},{"cell_type":"code","source":"from langchain.memory import ConversationBufferMemory\n\nmemory = ConversationBufferMemory()\nmemory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n\nmemory.load_memory_variables({})","metadata":{"execution":{"iopub.status.busy":"2023-10-22T14:46:45.904760Z","iopub.execute_input":"2023-10-22T14:46:45.905242Z","iopub.status.idle":"2023-10-22T14:46:48.306208Z","shell.execute_reply.started":"2023-10-22T14:46:45.905203Z","shell.execute_reply":"2023-10-22T14:46:48.305062Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"{'history': 'Human: hi\\nAI: whats up'}"},"metadata":{}}]},{"cell_type":"code","source":"memory = ConversationBufferMemory(return_messages=True)\nmemory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n\nmemory.load_memory_variables({})","metadata":{"execution":{"iopub.status.busy":"2023-10-22T14:47:35.277445Z","iopub.execute_input":"2023-10-22T14:47:35.278208Z","iopub.status.idle":"2023-10-22T14:47:35.286812Z","shell.execute_reply.started":"2023-10-22T14:47:35.278172Z","shell.execute_reply":"2023-10-22T14:47:35.285657Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"{'history': [HumanMessage(content='hi'), AIMessage(content='whats up')]}"},"metadata":{}}]},{"cell_type":"code","source":"from langchain import OpenAI, ConversationChain\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = \"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\"\n\nllm = OpenAI(temperature = 0)\nconversation = ConversationChain(\n    llm = llm,\n    verbose = True,\n    memory = ConversationBufferMemory()\n)\n\nconversation.predict(input=\"Hi there!\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T14:50:17.114561Z","iopub.execute_input":"2023-10-22T14:50:17.115198Z","iopub.status.idle":"2023-10-22T14:50:18.109948Z","shell.execute_reply.started":"2023-10-22T14:50:17.115163Z","shell.execute_reply":"2023-10-22T14:50:18.108720Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n\nHuman: Hi there!\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"\" Hi there! It's nice to meet you. How can I help you today?\""},"metadata":{}}]},{"cell_type":"code","source":"conversation.predict(input=\"I'm doing well! Just having a conversation with an AI.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T14:50:31.981591Z","iopub.execute_input":"2023-10-22T14:50:31.982563Z","iopub.status.idle":"2023-10-22T14:50:33.027466Z","shell.execute_reply.started":"2023-10-22T14:50:31.982524Z","shell.execute_reply":"2023-10-22T14:50:33.026519Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\nHuman: Hi there!\nAI:  Hi there! It's nice to meet you. How can I help you today?\nHuman: I'm doing well! Just having a conversation with an AI.\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"\" That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\""},"metadata":{}}]},{"cell_type":"code","source":"conversation.predict(input=\"Tell me about yourself.\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T14:50:50.188557Z","iopub.execute_input":"2023-10-22T14:50:50.188943Z","iopub.status.idle":"2023-10-22T14:50:51.490051Z","shell.execute_reply.started":"2023-10-22T14:50:50.188914Z","shell.execute_reply":"2023-10-22T14:50:51.488948Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\nHuman: Hi there!\nAI:  Hi there! It's nice to meet you. How can I help you today?\nHuman: I'm doing well! Just having a conversation with an AI.\nAI:  That's great! It's always nice to have a conversation with someone new. What would you like to talk about?\nHuman: Tell me about yourself.\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"\" Sure! I'm an AI created to help people with their everyday tasks. I'm programmed to understand natural language and provide helpful information. I'm also constantly learning and updating my knowledge base so I can provide more accurate and helpful answers.\""},"metadata":{}}]},{"cell_type":"markdown","source":"## Conversation Buffer Window","metadata":{}},{"cell_type":"code","source":"from langchain.memory import ConversationBufferWindowMemory\n\nmemory = ConversationBufferWindowMemory(k = 1) # saves the last message only\nmemory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\nmemory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n\nmemory.load_memory_variables({}) # it will load the last one as k = 1","metadata":{"execution":{"iopub.status.busy":"2023-10-22T14:54:15.726975Z","iopub.execute_input":"2023-10-22T14:54:15.727631Z","iopub.status.idle":"2023-10-22T14:54:15.736712Z","shell.execute_reply.started":"2023-10-22T14:54:15.727590Z","shell.execute_reply":"2023-10-22T14:54:15.735629Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"{'history': 'Human: not much you\\nAI: not much'}"},"metadata":{}}]},{"cell_type":"code","source":"from langchain import OpenAI, ConversationChain\nfrom langchain.memory import ConversationBufferWindowMemory\n\n\nllm = OpenAI(temperature = 0)\nconversation = ConversationChain(\n    llm = llm,\n    memory = ConversationBufferWindowMemory(k = 2),\n    verbose = True\n)\n\nconversation.predict(input=\"Hi, what's up?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T14:59:54.105494Z","iopub.execute_input":"2023-10-22T14:59:54.106064Z","iopub.status.idle":"2023-10-22T14:59:54.880017Z","shell.execute_reply.started":"2023-10-22T14:59:54.106030Z","shell.execute_reply":"2023-10-22T14:59:54.878902Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n\nHuman: Hi, what's up?\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"\" Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\""},"metadata":{}}]},{"cell_type":"code","source":"conversation.predict(input=\"What's their issues?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:00:27.932295Z","iopub.execute_input":"2023-10-22T15:00:27.932828Z","iopub.status.idle":"2023-10-22T15:00:28.721612Z","shell.execute_reply.started":"2023-10-22T15:00:27.932786Z","shell.execute_reply":"2023-10-22T15:00:28.720439Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\nHuman: Hi, what's up?\nAI:  Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\nHuman: What's their issues?\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"\" The customer is having trouble connecting to their Wi-Fi network. I'm helping them troubleshoot the issue and get them connected.\""},"metadata":{}}]},{"cell_type":"code","source":"conversation.predict(input=\"Is it going well?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:00:42.123494Z","iopub.execute_input":"2023-10-22T15:00:42.124748Z","iopub.status.idle":"2023-10-22T15:00:42.783622Z","shell.execute_reply.started":"2023-10-22T15:00:42.124707Z","shell.execute_reply":"2023-10-22T15:00:42.782650Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\nHuman: Hi, what's up?\nAI:  Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\nHuman: What's their issues?\nAI:  The customer is having trouble connecting to their Wi-Fi network. I'm helping them troubleshoot the issue and get them connected.\nHuman: Is it going well?\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"\" Yes, it's going well so far. We've already identified the problem and are now working on a solution.\""},"metadata":{}}]},{"cell_type":"code","source":"conversation.predict(input=\"What's the solution?\") # The first one will disapear","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:01:09.314963Z","iopub.execute_input":"2023-10-22T15:01:09.315369Z","iopub.status.idle":"2023-10-22T15:01:10.142230Z","shell.execute_reply.started":"2023-10-22T15:01:09.315336Z","shell.execute_reply":"2023-10-22T15:01:10.141137Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\nHuman: What's their issues?\nAI:  The customer is having trouble connecting to their Wi-Fi network. I'm helping them troubleshoot the issue and get them connected.\nHuman: Is it going well?\nAI:  Yes, it's going well so far. We've already identified the problem and are now working on a solution.\nHuman: What's the solution?\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"\" The solution is to reset the router and reconfigure the settings. We're currently in the process of doing that.\""},"metadata":{}}]},{"cell_type":"markdown","source":"## Conversation Token Buffer","metadata":{}},{"cell_type":"code","source":"from langchain.memory import ConversationTokenBufferMemory\nfrom langchain.chat_models import ChatOpenAI\nfrom langchain.llms import OpenAI\nllm = ChatOpenAI(temperature=0.0)\n\nmemory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\nmemory.save_context({\"input\": \"AI is what?!\"},\n                    {\"output\": \"Amazing!\"})\nmemory.save_context({\"input\": \"Backpropagation is what?\"},\n                    {\"output\": \"Beautiful!\"})\nmemory.save_context({\"input\": \"Chatbots are what?\"}, \n                    {\"output\": \"Charming!\"})\n\nmemory.load_memory_variables({})","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:08:05.372383Z","iopub.execute_input":"2023-10-22T15:08:05.372956Z","iopub.status.idle":"2023-10-22T15:08:06.462042Z","shell.execute_reply.started":"2023-10-22T15:08:05.372912Z","shell.execute_reply":"2023-10-22T15:08:06.460843Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'history': 'AI: Beautiful!\\nHuman: Chatbots are what?\\nAI: Charming!'}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Conversation Summary Memory","metadata":{}},{"cell_type":"code","source":"from langchain.llms import OpenAI\nfrom langchain.chains import ConversationChain\nfrom langchain.memory import ConversationSummaryMemory\n    \nllm = OpenAI(temperature=0)\nconversation_with_summary = ConversationChain(\n    llm=llm,\n    memory=ConversationSummaryMemory(llm=OpenAI()),\n    verbose=True\n)\n    \nconversation_with_summary.predict(input=\"Hi, what's up?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:21:59.801220Z","iopub.execute_input":"2023-10-22T15:21:59.801672Z","iopub.status.idle":"2023-10-22T15:22:01.175631Z","shell.execute_reply.started":"2023-10-22T15:21:59.801634Z","shell.execute_reply":"2023-10-22T15:22:01.174526Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n\nHuman: Hi, what's up?\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"\" Hi there! I'm doing great. I'm currently helping a customer with a technical issue. How about you?\""},"metadata":{}}]},{"cell_type":"code","source":"conversation_with_summary.predict(input=\"Tell me more about it!\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:22:15.233529Z","iopub.execute_input":"2023-10-22T15:22:15.233940Z","iopub.status.idle":"2023-10-22T15:22:17.124705Z","shell.execute_reply.started":"2023-10-22T15:22:15.233910Z","shell.execute_reply":"2023-10-22T15:22:17.123613Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n\nThe human asks the AI what they are doing. The AI responds that they are helping a customer with a technical issue.\nHuman: Tell me more about it!\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"\" Sure! The customer is having trouble connecting to their home Wi-Fi network. I'm helping them troubleshoot the issue and figure out what the problem is.\""},"metadata":{}}]},{"cell_type":"code","source":"conversation_with_summary.predict(input=\"Very cool -- what is the scope of the project?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:22:23.106437Z","iopub.execute_input":"2023-10-22T15:22:23.106882Z","iopub.status.idle":"2023-10-22T15:22:26.735289Z","shell.execute_reply.started":"2023-10-22T15:22:23.106846Z","shell.execute_reply":"2023-10-22T15:22:26.734103Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\n\nThe human asks the AI what they are doing and the AI responds that they are helping a customer with a technical issue related to their home Wi-Fi network, troubleshooting and trying to figure out the cause of the problem.\nHuman: Very cool -- what is the scope of the project?\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"\" The scope of the project is to troubleshoot the customer's home Wi-Fi network and identify the cause of the issue. I'm currently running a series of tests to determine the source of the problem. Once I have identified the cause, I will be able to provide the customer with a solution.\""},"metadata":{}}]},{"cell_type":"markdown","source":"## Conversation Summary Buffer Memory","metadata":{}},{"cell_type":"code","source":"from langchain.memory import ConversationSummaryBufferMemory\n\nschedule = \"I have a lecture at 9am about probability. \\\nThere will be a quiz at the lecture. \\\nAfter that I am going to have a break then go to my graduation project team \\\nour project is about v2x and helping avoiding accidents. \\\nAt Noon, lunch at the italian resturant with my friend Lisa. \\\nAt night I will go to cinema watch the latest Cristover Nolan film with my friends\"\n\nmemory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)\nmemory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\nmemory.save_context({\"input\": \"Not much, just hanging\"},\n                    {\"output\": \"Cool\"})\nmemory.save_context({\"input\": \"What is on the schedule today?\"}, \n                    {\"output\": f\"{schedule}\"})\n\nmemory.load_memory_variables({})","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:17:00.033472Z","iopub.execute_input":"2023-10-22T15:17:00.034671Z","iopub.status.idle":"2023-10-22T15:17:03.089642Z","shell.execute_reply.started":"2023-10-22T15:17:00.034592Z","shell.execute_reply":"2023-10-22T15:17:03.088277Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'history': 'System: The human greets the AI and the AI responds with a casual greeting. The human mentions that they are not doing much and the AI responds with a casual remark.\\nHuman: What is on the schedule today?\\nAI: I have a lecture at 9am about probability. There will be a quiz at the lecture. After that I am going to have a break then go to my graduation project team our project is about v2x and helping avoiding accidents. At Noon, lunch at the italian resturant with my friend Lisa. At night I will go to cinema watch the latest Cristover Nolan film with my friends'}"},"metadata":{}}]},{"cell_type":"code","source":"conversation = ConversationChain(\n    llm=llm, \n    memory = memory,\n    verbose=True\n)\n\nconversation.predict(input=\"What would be the film at the cinema?\")","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:17:22.350477Z","iopub.execute_input":"2023-10-22T15:17:22.351022Z","iopub.status.idle":"2023-10-22T15:17:30.969435Z","shell.execute_reply.started":"2023-10-22T15:17:22.350984Z","shell.execute_reply":"2023-10-22T15:17:30.968304Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"\n\n\u001b[1m> Entering new ConversationChain chain...\u001b[0m\nPrompt after formatting:\n\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n\nCurrent conversation:\nSystem: The human greets the AI and the AI responds with a casual greeting. The human mentions that they are not doing much and the AI responds with a casual remark.\nHuman: What is on the schedule today?\nAI: I have a lecture at 9am about probability. There will be a quiz at the lecture. After that I am going to have a break then go to my graduation project team our project is about v2x and helping avoiding accidents. At Noon, lunch at the italian resturant with my friend Lisa. At night I will go to cinema watch the latest Cristover Nolan film with my friends\nHuman: What would be the film at the cinema?\nAI:\u001b[0m\n\n\u001b[1m> Finished chain.\u001b[0m\n","output_type":"stream"},{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"'The latest Christopher Nolan film is called \"Tenet.\" It is a science fiction action-thriller that involves time manipulation and espionage. The film has received positive reviews for its complex plot and stunning visuals.'"},"metadata":{}}]},{"cell_type":"code","source":"memory.load_memory_variables({})","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:20:12.285134Z","iopub.execute_input":"2023-10-22T15:20:12.286922Z","iopub.status.idle":"2023-10-22T15:20:12.297781Z","shell.execute_reply.started":"2023-10-22T15:20:12.286872Z","shell.execute_reply":"2023-10-22T15:20:12.296428Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'history': 'System: The human greets the AI and the AI responds with a casual greeting. The human mentions that they are not doing much and the AI responds with a casual remark. The human asks what is on the schedule today and the AI responds with a detailed itinerary, including a lecture, a break, a graduation project meeting, lunch with a friend, and a trip to the cinema with friends to watch a Christopher Nolan film.\\nHuman: What would be the film at the cinema?\\nAI: The latest Christopher Nolan film is called \"Tenet.\" It is a science fiction action-thriller that involves time manipulation and espionage. The film has received positive reviews for its complex plot and stunning visuals.'}"},"metadata":{}}]},{"cell_type":"markdown","source":"## Conversation Entity Memory","metadata":{}},{"cell_type":"code","source":"from langchain.memory import ConversationEntityMemory\n\nllm = OpenAI(temperature = 0)\nmemory = ConversationEntityMemory(llm = llm)\n_input = {\"input\": \"Ahmed and Anas are working on Google Brain\"}\nmemory.load_memory_variables(_input)\nmemory.save_context(\n    _input,\n    {\"output\": \" That sounds like a great postion! What kind of work ther are doing there?\"}\n)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:37:52.007951Z","iopub.execute_input":"2023-10-22T15:37:52.008398Z","iopub.status.idle":"2023-10-22T15:37:53.716570Z","shell.execute_reply.started":"2023-10-22T15:37:52.008367Z","shell.execute_reply":"2023-10-22T15:37:53.715482Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"memory.load_memory_variables({\"input\": 'who is Ahmed'})","metadata":{"execution":{"iopub.status.busy":"2023-10-22T15:38:17.046546Z","iopub.execute_input":"2023-10-22T15:38:17.046930Z","iopub.status.idle":"2023-10-22T15:38:17.332805Z","shell.execute_reply.started":"2023-10-22T15:38:17.046903Z","shell.execute_reply":"2023-10-22T15:38:17.331640Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"{'history': 'Human: Ahmed and Anas are working on Google Brain\\nAI:  That sounds like a great postion! What kind of work ther are doing there?',\n 'entities': {'Ahmed': 'Ahmed is working on Google Brain.'}}"},"metadata":{}}]}]}