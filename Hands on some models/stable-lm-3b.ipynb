{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers accelerate","metadata":{"execution":{"iopub.status.busy":"2023-10-04T12:45:55.271269Z","iopub.execute_input":"2023-10-04T12:45:55.271584Z","iopub.status.idle":"2023-10-04T12:46:04.405820Z","shell.execute_reply.started":"2023-10-04T12:45:55.271555Z","shell.execute_reply":"2023-10-04T12:46:04.404659Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T12:46:27.449344Z","iopub.execute_input":"2023-10-04T12:46:27.449767Z","iopub.status.idle":"2023-10-04T12:46:27.806962Z","shell.execute_reply.started":"2023-10-04T12:46:27.449728Z","shell.execute_reply":"2023-10-04T12:46:27.806089Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba17665397aa49558efeaaa90f6d184b"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2023-10-04T12:47:32.812458Z","iopub.execute_input":"2023-10-04T12:47:32.812816Z","iopub.status.idle":"2023-10-04T12:47:34.276218Z","shell.execute_reply.started":"2023-10-04T12:47:32.812790Z","shell.execute_reply":"2023-10-04T12:47:34.275266Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"model_name = \"stabilityai/stablelm-3b-4e1t\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n  model_name,\n  trust_remote_code=True,\n  torch_dtype=\"auto\"\n)\nmodel.cuda()","metadata":{"execution":{"iopub.status.busy":"2023-10-04T12:50:50.378496Z","iopub.execute_input":"2023-10-04T12:50:50.378836Z","iopub.status.idle":"2023-10-04T12:58:19.278534Z","shell.execute_reply.started":"2023-10-04T12:50:50.378809Z","shell.execute_reply":"2023-10-04T12:58:19.277466Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/5.59G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4461f0efb00447f08015efa53f0bce04"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"418832e87e6c4faea542e403b8a42026"}},"metadata":{}},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"StableLMEpochForCausalLM(\n  (model): StableLMEpochModel(\n    (embed_tokens): Embedding(50304, 2560)\n    (layers): ModuleList(\n      (0-31): 32 x DecoderLayer(\n        (self_attn): Attention(\n          (q_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (k_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (v_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (o_proj): Linear(in_features=2560, out_features=2560, bias=False)\n          (rotary_emb): RotaryEmbedding()\n        )\n        (mlp): MLP(\n          (gate_proj): Linear(in_features=2560, out_features=6912, bias=False)\n          (up_proj): Linear(in_features=2560, out_features=6912, bias=False)\n          (down_proj): Linear(in_features=6912, out_features=2560, bias=False)\n          (act_fn): SiLU()\n        )\n        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n      )\n    )\n    (norm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n  )\n  (lm_head): Linear(in_features=2560, out_features=50304, bias=False)\n)"},"metadata":{}}]},{"cell_type":"code","source":"inputs = tokenizer(\n\"Question: How do you import a csv file in Python \\n Answer: import pandas as pd \",\nreturn_tensors=\"pt\"\n).to(\"cuda\")\ntokens = model.generate(\n    **inputs,\n    max_new_tokens = 100,\n    temperature = 0.75,\n    top_p = 0.95,\n    do_sample = True,\n)\nprint(tokenizer.decode(tokens[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-10-04T12:58:21.734996Z","iopub.execute_input":"2023-10-04T12:58:21.735765Z","iopub.status.idle":"2023-10-04T12:58:27.913635Z","shell.execute_reply.started":"2023-10-04T12:58:21.735733Z","shell.execute_reply":"2023-10-04T12:58:27.912752Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Question: How do you import a csv file in Python \n Answer: import pandas as pd \n#dataframe = pd.read_csv('data/purchase_data.csv') \ndata = pd.read_csv('data/purchase_data.csv')\nprint(data.head())\n\nQuestion: How do you import a csv file in Python \n Answer: import pandas as pd \n#dataframe = pd.read_csv('data/purchase_data.csv') \ndata = pd.read_csv('data/p\n","output_type":"stream"}]},{"cell_type":"code","source":"inputs = tokenizer(\n\"This is a great tweet with hashtags about a new product launch of Stable LM, a new text generation AI. Here goes the tweet: \\n\",\nreturn_tensors=\"pt\"\n).to(\"cuda\")\ntokens = model.generate(\n    **inputs,\n    max_new_tokens = 100,\n    temperature = 0.75,\n    top_p = 0.95,\n    do_sample = True,\n)\nprint(tokenizer.decode(tokens[0], skip_special_tokens=True))","metadata":{"execution":{"iopub.status.busy":"2023-10-04T12:58:27.915228Z","iopub.execute_input":"2023-10-04T12:58:27.915884Z","iopub.status.idle":"2023-10-04T12:58:30.977415Z","shell.execute_reply.started":"2023-10-04T12:58:27.915850Z","shell.execute_reply":"2023-10-04T12:58:30.976345Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"This is a great tweet with hashtags about a new product launch of Stable LM, a new text generation AI. Here goes the tweet: \n\nStable LM is a new text generation AI, and we're releasing a special edition of the first 5,000 words generated by this system for free. It's a story about an AI that learns to create better text, and you can read it here: https://twitter.com/stable_lm/status/1161448256064125041\n\nHere is the link: https://twitter.com/stable_lm/status/116144825606412\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}